{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8b33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import configparser\n",
    "from PIL import Image\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy, BinaryCrossentropy\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import shutil\n",
    "import sys\n",
    "import glob\n",
    "import traceback\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Conv2D, MaxPool2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import  BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "#from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "MODEL = \"model\"\n",
    "TRAIN = \"train\"\n",
    "EVAL = \"eval\"\n",
    "MASK = \"mask\"\n",
    "INFER  = \"infer\"\n",
    "TILEDINFER = \"tiledinfer\"\n",
    "BEST_MODEL_FILE = \"best_model.h5\"\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "os.environ[\"TF_ENABLE_GPU_GARBAGE_COLLECTION\"]=\"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07546304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigParser:\n",
    "\n",
    "    def __init__(self, config_path):\n",
    "        print(\"==== ConfigParser {}\".format(config_path))\n",
    "        if not os.path.exists(config_path):\n",
    "            raise Exception(\"Not found config_path {}\".format(config_path))\n",
    "\n",
    "        try:\n",
    "            self.parse(config_path)\n",
    "            self.dump_all()\n",
    "        except Exception as ex:\n",
    "            print(\"==== ConfigParser Exception -----------------------{}\".format(ex))\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def parse(self, config_path):\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_path)\n",
    "        self.dict = {s: {i[0]: i[1] for i in config.items(s)} for s in config.sections()}\n",
    "\n",
    "    def dump_all(self):\n",
    "        pprint.pprint(self.dict)\n",
    "\n",
    "    def get(self, section, name, dvalue=None):\n",
    "        value = None\n",
    "        try:\n",
    "            value = self.dict[section][name]\n",
    "            value = eval(value)\n",
    "        except:\n",
    "            value = dvalue\n",
    "            print(\"=== WARNING: Not found [{}]  {}, return default value {}\".format(section, name, value))\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fd543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMaskDataset:\n",
    "\n",
    "    def __init__(self, config_file):\n",
    "        config = ConfigParser(config_file)\n",
    "        self.image_width = config.get(MODEL, \"image_width\")\n",
    "        self.image_height = config.get(MODEL, \"image_height\")\n",
    "        self.image_channels = config.get(MODEL, \"image_channels\")\n",
    "        self.train_dataset = [config.get(TRAIN, \"image_datapath\"),\n",
    "                              config.get(TRAIN, \"mask_datapath\")]\n",
    "\n",
    "        self.eval_dataset = [config.get(EVAL, \"image_datapath\"),\n",
    "                             config.get(EVAL, \"mask_datapath\")]\n",
    "\n",
    "        self.binarize = config.get(MASK, \"binarize\")\n",
    "        self.threshold = config.get(MASK, \"threshold\")\n",
    "        self.blur_mask = config.get(MASK, \"blur\")\n",
    "\n",
    "        # Fixed blur_size\n",
    "        self.blur_size = (3, 3)\n",
    "\n",
    "    def create(self, dataset=TRAIN, debug=False):\n",
    "        if dataset not in [TRAIN, EVAL]:\n",
    "            raise Exception(\"Invalid dataset\")\n",
    "        image_datapath = None\n",
    "        mask_datapath = None\n",
    "\n",
    "        [image_datapath, mask_datapath] = self.train_dataset\n",
    "        if dataset == EVAL:\n",
    "            [image_datapath, mask_datapath] = self.eval_dataset\n",
    "\n",
    "        image_files = glob.glob(image_datapath + \"/*.jpg\")\n",
    "        image_files += glob.glob(image_datapath + \"/*.png\")\n",
    "        image_files += glob.glob(image_datapath + \"/*.bmp\")\n",
    "        image_files += glob.glob(image_datapath + \"/*.tif\")\n",
    "        image_files = sorted(image_files)\n",
    "\n",
    "        mask_files = None\n",
    "        if os.path.exists(mask_datapath):\n",
    "            mask_files = glob.glob(mask_datapath + \"/*.jpg\")\n",
    "            mask_files += glob.glob(mask_datapath + \"/*.png\")\n",
    "            mask_files += glob.glob(mask_datapath + \"/*.bmp\")\n",
    "            mask_files += glob.glob(mask_datapath + \"/*.tif\")\n",
    "            mask_files = sorted(mask_files)\n",
    "\n",
    "            if len(image_files) != len(mask_files):\n",
    "                raise Exception(\"FATAL: Images and masks unmatched\")\n",
    "\n",
    "        num_images = len(image_files)\n",
    "        if num_images == 0:\n",
    "            raise Exception(\"FATAL: Not found image files\")\n",
    "\n",
    "        X = np.zeros((num_images, self.image_height, self.image_width, self.image_channels), dtype=np.uint8)\n",
    "        Y = np.zeros((num_images, self.image_height, self.image_width, 1), dtype=bool)\n",
    "\n",
    "        for n, image_file in tqdm(enumerate(image_files), total=len(image_files)):\n",
    "            image = cv2.imread(image_file)\n",
    "            image = cv2.resize(image, dsize=(self.image_height, self.image_width), interpolation=cv2.INTER_NEAREST)\n",
    "            X[n] = image\n",
    "\n",
    "            if mask_files is not None:\n",
    "                mask = cv2.imread(mask_files[n])\n",
    "                mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "                mask = cv2.resize(mask, dsize=(self.image_height, self.image_width), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "                # Binarize mask\n",
    "                if self.binarize:\n",
    "                    mask[mask < self.threshold] = 0\n",
    "                    mask[mask >= self.threshold] = 255\n",
    "\n",
    "                # Blur mask\n",
    "                if self.blur_mask:\n",
    "                    mask = cv2.blur(mask, self.blur_size)\n",
    "\n",
    "                mask = np.expand_dims(mask, axis=-1)\n",
    "                Y[n] = mask\n",
    "\n",
    "#                 if debug:\n",
    "#                     cv2.imshow(\"---\", mask)\n",
    "#                     cv2.waitKey(27)\n",
    "#                     input(\"XX\")\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "060ab9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    y_true_f = K.cast(y_true_f, 'float32')\n",
    "    y_pred_f = K.cast(y_pred_f, 'float32')\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2.0 * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "   \n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss / 2.0\n",
    "\n",
    "def jacard_similarity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Intersection-Over-Union (IoU), also known as the Jaccard Index\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.cast(y_true_f, 'float32')\n",
    "    y_pred_f = K.cast(y_pred_f, 'float32')\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum((y_true_f + y_pred_f) - (y_true_f * y_pred_f))\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def jacard_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Intersection-Over-Union (IoU), also known as the Jaccard loss\n",
    "    \"\"\"\n",
    "    return 1 - jacard_similarity(y_true, y_pred)\n",
    "\n",
    "def iou_coef(y_true, y_pred):\n",
    "    return jacard_similarity(y_true, y_pred)\n",
    "\n",
    "def iou_loss(y_true, y_pred):\n",
    "    return 1 - jacard_similarity(y_true, y_pred)\n",
    "\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Structural Similarity Index (SSIM) loss\n",
    "    \"\"\"\n",
    "    y_true_f = K.cast(y_true, 'float32')\n",
    "    y_pred_f = K.cast(y_pred, 'float32')\n",
    "\n",
    "    return 1 - tf.image.ssim(y_true_f, y_pred_f, max_val=1)\n",
    "\n",
    "def basnet_hybrid_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Hybrid loss proposed in BASNET (https://arxiv.org/pdf/2101.04704.pdf)\n",
    "    The hybrid loss is a combination of the binary cross entropy, structural similarity\n",
    "    and intersection-over-union losses, which guide the network to learn\n",
    "    three-level (i.e., pixel-, patch- and map- level) hierarchy representations.\n",
    "    \"\"\"\n",
    "    bce_loss = BinaryCrossentropy(from_logits=False)\n",
    "    bce_loss = bce_loss(y_true, y_pred)\n",
    "\n",
    "    ms_ssim_loss = ssim_loss(y_true, y_pred)\n",
    "    jac_loss     = jacard_loss(y_true, y_pred)\n",
    "\n",
    "    loss = bce_loss + ms_ssim_loss + jac_loss\n",
    "    return loss/3.0\n",
    "\n",
    "def bce_iou_loss(y_true, y_pred):\n",
    "    bce_loss = BinaryCrossentropy(from_logits=False)\n",
    "    loss1 = bce_loss(y_true, y_pred)\n",
    "    loss2 = iou_loss(y_true, y_pred)\n",
    "\n",
    "    loss = loss1 + loss2\n",
    "    return loss/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochChangeCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, eval_dir, metrics=[\"accuracy\", \"val_accuracy\"]):\n",
    "        self.eval_dir = eval_dir\n",
    "        self.metrics = metrics\n",
    "\n",
    "        if os.path.exists(self.eval_dir):\n",
    "            shutil.rmtree(self.eval_dir)\n",
    "\n",
    "        if not os.path.exists(self.eval_dir):\n",
    "            os.makedirs(self.eval_dir)\n",
    "\n",
    "        self.train_losses_file = os.path.join(self.eval_dir, \"train_losses.csv\")\n",
    "        self.train_accuracies_file = os.path.join(self.eval_dir, \"train_metrics.csv\")\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(self.train_losses_file):\n",
    "                with open(self.train_losses_file, \"w\") as f:\n",
    "                    header = \"epoch, loss, val_loss\\n\"\n",
    "                    f.write(header)\n",
    "        except Exception as ex:\n",
    "            traceback.print_exc()\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(self.train_accuracies_file):\n",
    "                with open(self.train_accuracies_file, \"w\") as f:\n",
    "                    header = \"epoch,\" + metrics[0] + \",\" + metrics[1] + \",\" + \"\\n\"\n",
    "                    f.write(header)\n",
    "        except Exception as ex:\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        acc = logs.get(self.metrics[0], logs.get('acc', 0))\n",
    "        val_acc = logs.get(self.metrics[1], logs.get('val_acc', 0))\n",
    "        loss = logs.get('loss', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "\n",
    "        NL = \"\\n\"\n",
    "\n",
    "        try:\n",
    "            with open(self.train_losses_file, \"a\") as f:\n",
    "                losses = \"{}, {:.4f}, {:.4f}\".format(epoch, loss, val_loss)\n",
    "                f.write(losses + NL)\n",
    "        except Exception as ex:\n",
    "            traceback.print_exc()\n",
    "\n",
    "        try:\n",
    "            with open(self.train_accuracies_file, \"a\") as f:\n",
    "                accuracies = \"{}, {:.4f}, {:.4f}\".format(epoch, acc, val_acc)\n",
    "                f.write(accuracies + NL)\n",
    "        except Exception as ex:\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53dddf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayScaleImageWriter:\n",
    "\n",
    "    def __init__(self, image_format=\".jpg\"):\n",
    "        self.image_format = image_format\n",
    "\n",
    "    def save(self, data, output_dir, name, factor=255.0):\n",
    "        h, w = data.shape[:2]\n",
    "        image = Image.new(\"L\", (w, h))\n",
    "        print(f\" image w: {w} h: {h}\")\n",
    "        for i in range(w):\n",
    "            for j in range(h):\n",
    "                z = data[j][i][0] if isinstance(data[j][i], list) else data[j][i]\n",
    "                v = int(z * factor)\n",
    "                image.putpixel((i, j), v)\n",
    "\n",
    "        image_filepath = os.path.join(output_dir, name + self.image_format)\n",
    "        image.save(image_filepath)\n",
    "        print(f\"=== Saved {image_filepath}\")\n",
    "\n",
    "    def save_resized(self, data, resized, output_dir, name, factor=255.0):\n",
    "        h, w = data.shape[:2]\n",
    "        image = Image.new(\"L\", (w, h))\n",
    "        print(f\" image w: {w} h: {h}\")\n",
    "        for i in range(w):\n",
    "            for j in range(h):\n",
    "                z = data[j][i][0] if isinstance(data[j][i], list) else data[j][i]\n",
    "                v = int(z * factor)\n",
    "                image.putpixel((i, j), v)\n",
    "\n",
    "        image_filepath = os.path.join(output_dir, name + self.image_format)\n",
    "        print(f\"== resized to {resized}\")\n",
    "        image = image.resize(resized)\n",
    "        image.save(image_filepath)\n",
    "        image = image.convert(\"RGB\")\n",
    "        print(f\"=== Saved {image_filepath}\")\n",
    "        return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97456e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorflowUNet:\n",
    "    \n",
    "    def __init__(self, config_file):\n",
    "        \n",
    "        self.set_seed()\n",
    "        self.config_file = config_file\n",
    "        self.config    = ConfigParser(config_file)\n",
    "        image_height   = self.config.get(MODEL, \"image_height\")\n",
    "        image_width    = self.config.get(MODEL, \"image_width\")\n",
    "        image_channels = self.config.get(MODEL, \"image_channels\")\n",
    "        num_classes    = self.config.get(MODEL, \"num_classes\")\n",
    "        base_filters   = self.config.get(MODEL, \"base_filters\")\n",
    "        num_layers     = self.config.get(MODEL, \"num_layers\")\n",
    "        self.model     = self.create(num_classes, image_height, image_width, image_channels, \n",
    "                                base_filters = base_filters, num_layers = num_layers)\n",
    "        \n",
    "        learning_rate  = self.config.get(MODEL, \"learning_rate\")\n",
    "        clipvalue      = self.config.get(MODEL, \"clipvalue\", 0.2)\n",
    "\n",
    "        self.optimizer = Adam(learning_rate = learning_rate, \n",
    "             beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, \n",
    "             clipvalue=clipvalue,  #2023/0626\n",
    "             amsgrad=False)\n",
    "        print(\"=== Optimizer Adam learning_rate {} clipvalue {}\".format(learning_rate, clipvalue))\n",
    "\n",
    "        self.model_loaded = False\n",
    "\n",
    "        # 2023/05/20 Modified to read loss and metrics from train_eval_infer.config file.\n",
    "        binary_crossentropy = tf.keras.metrics.binary_crossentropy\n",
    "        binary_accuracy     = tf.keras.metrics.binary_accuracy\n",
    "\n",
    "        # Default loss and metrics functions\n",
    "        self.loss    = binary_crossentropy\n",
    "        self.metrics = [binary_accuracy]\n",
    "\n",
    "        # Read a loss function name from our config file, and eval it.\n",
    "        # loss = \"binary_crossentropy\"\n",
    "        self.loss  = eval(self.config.get(MODEL, \"loss\"))\n",
    "\n",
    "        # Read a list of metrics function names, ant eval each of the list,\n",
    "        # metrics = [\"binary_accuracy\"]\n",
    "        metrics  = self.config.get(MODEL, \"metrics\")\n",
    "        self.metrics = []\n",
    "        for metric in metrics:\n",
    "            self.metrics.append(eval(metric))\n",
    "\n",
    "        print(\"--- loss    {}\".format(self.loss))\n",
    "        print(\"--- metrics {}\".format(self.metrics))\n",
    "\n",
    "        #self.model.trainable = self.trainable\n",
    "\n",
    "        self.model.compile(optimizer = self.optimizer, loss= self.loss, metrics = self.metrics)\n",
    "\n",
    "        show_summary = self.config.get(MODEL, \"show_summary\")\n",
    "        if show_summary:\n",
    "            self.model.summary()\n",
    "            \n",
    "            \n",
    "    def set_seed(self, seed=137):\n",
    "        print(\"=== set seed {}\".format(seed))\n",
    "        random.seed    = seed\n",
    "        np.random.seed = seed\n",
    "        tf.random.set_seed(seed)\n",
    "        \n",
    "    def create(self, num_classes, image_height, image_width, image_channels,\n",
    "               base_filters=16, num_layers=5):\n",
    "        # inputs\n",
    "        print(\"Input image_height {} image_width {} image_channels {}\".format(image_height, image_width, image_channels))\n",
    "        inputs = Input((image_height, image_width, image_channels))\n",
    "        s = Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "        # normalization is False on default.\n",
    "        normalization = self.config.get(MODEL, \"normalization\", dvalue=False)\n",
    "        print(\"--- normalization {}\".format(normalization))\n",
    "        # Encoder\n",
    "        dropout_rate = self.config.get(MODEL, \"dropout_rate\")\n",
    "        enc = []\n",
    "        kernel_size = (3, 3)\n",
    "        pool_size = (2, 2)\n",
    "        dilation = (2, 2)\n",
    "        strides = (1, 1)\n",
    "        # <experiment on=\"2023/06/20\">\n",
    "        # [model]\n",
    "        # Specify a tuple of base kernel size of odd number something like this:\n",
    "        # base_kernels = (5,5)\n",
    "        base_kernels = self.config.get(MODEL, \"base_kernels\", dvalue=(3, 3))\n",
    "        (k, k) = base_kernels\n",
    "        kernel_sizes = []\n",
    "        for n in range(num_layers):\n",
    "            kernel_sizes += [(k, k)]\n",
    "            k -= 2\n",
    "            if k < 3:\n",
    "                k = 3\n",
    "        rkernel_sizes = kernel_sizes[::-1]\n",
    "        rkernel_sizes = rkernel_sizes[1:]\n",
    "        # kernel_sizes will become a list [(7,7),(5,5), (3,3),(3,3)...] if base_kernels were (7,7)\n",
    "        print(\"--- kernel_size   {}\".format(kernel_sizes))\n",
    "        print(\"--- rkernel_size  {}\".format(rkernel_sizes))\n",
    "        # </experiment>\n",
    "        try:\n",
    "            dilation_ = self.config.get(MODEL, \"dilation\")\n",
    "            (d1, d2) = dilation_\n",
    "            if d1 == d2:\n",
    "                dilation = dilation_\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        dilations = []\n",
    "        (d, d) = dilation\n",
    "        for n in range(num_layers):\n",
    "            dilations += [(d, d)]\n",
    "            d -= 1\n",
    "            if d < 1:\n",
    "                d = 1\n",
    "        rdilations = dilations[::-1]\n",
    "        rdilations = rdilations[1:]\n",
    "\n",
    "        print(\"=== dilations  {}\".format(dilations))\n",
    "        print(\"=== rdilations {}\".format(rdilations))\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            filters = base_filters * (2**i)\n",
    "            kernel_size = kernel_sizes[i]\n",
    "            dilation = dilations[i]\n",
    "\n",
    "            print(\"--- kernel_size {}\".format(kernel_size))\n",
    "            print(\"--- dilation {}\".format(dilation))\n",
    "\n",
    "            c = Conv2D(filters, kernel_size, strides=strides, activation=relu,\n",
    "                       kernel_initializer='he_normal', dilation_rate=dilation, padding='same')(s)\n",
    "            if normalization:\n",
    "                c = BatchNormalization()(c)\n",
    "            c = Dropout(dropout_rate * i)(c)\n",
    "            c = Conv2D(filters, kernel_size, strides=strides, activation=relu,\n",
    "                       kernel_initializer='he_normal', dilation_rate=dilation, padding='same')(c)\n",
    "            if normalization:\n",
    "                c = BatchNormalization()(c)\n",
    "            if i < (num_layers - 1):\n",
    "                p = MaxPool2D(pool_size=pool_size)(c)\n",
    "                s = p\n",
    "            enc.append(c)\n",
    "\n",
    "        enc_len = len(enc)\n",
    "        enc.reverse()\n",
    "        n = 0\n",
    "        c = enc[n]\n",
    "\n",
    "        # --- Decoder\n",
    "        for i in range(num_layers - 1):\n",
    "            kernel_size = rkernel_sizes[i]\n",
    "            dilation = rdilations[i]\n",
    "            print(\"+++ kernel_size {}\".format(kernel_size))\n",
    "            print(\"+++ dilation {}\".format(dilation))\n",
    "\n",
    "            f = enc_len - 2 - i\n",
    "            filters = base_filters * (2**f)\n",
    "            u = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(c)\n",
    "            n += 1\n",
    "            u = concatenate([u, enc[n]])\n",
    "            u = Conv2D(filters, kernel_size, strides=strides, activation=relu,\n",
    "                       kernel_initializer='he_normal', dilation_rate=dilation, padding='same')(u)\n",
    "            # 2023/06/20\n",
    "            if normalization:\n",
    "                u = BatchNormalization()(u)\n",
    "            u = Dropout(dropout_rate * f)(u)\n",
    "            u = Conv2D(filters, kernel_size, strides=strides, activation=relu,\n",
    "                       kernel_initializer='he_normal', dilation_rate=dilation, padding='same')(u)\n",
    "            # 2023/06/25\n",
    "            if normalization:\n",
    "                u = BatchNormalization()(u)\n",
    "            c = u\n",
    "\n",
    "        # outouts\n",
    "        outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(c)\n",
    "\n",
    "        # create Model\n",
    "        model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def create_dirs(self, eval_dir, model_dir):\n",
    "        # 2023/06/20\n",
    "        dt_now = str(datetime.datetime.now())\n",
    "        dt_now = dt_now.replace(\":\", \"_\").replace(\" \", \"_\")\n",
    "        create_backup = self.config.get(TRAIN, \"create_backup\", False)\n",
    "        if os.path.exists(eval_dir):\n",
    "            # if create_backup flag is True, move previous eval_dir to *_bak\n",
    "            if create_backup:\n",
    "                moved_dir = eval_dir + \"_\" + dt_now + \"_bak\"\n",
    "                shutil.move(eval_dir, moved_dir)\n",
    "                print(\"--- Moved to {}\".format(moved_dir))\n",
    "            else:\n",
    "                shutil.rmtree(eval_dir)\n",
    "\n",
    "        if not os.path.exists(eval_dir):\n",
    "            os.makedirs(eval_dir)\n",
    "\n",
    "        if os.path.exists(model_dir):\n",
    "            # if create_backup flag is True, move previous model_dir to *_bak\n",
    "            if create_backup:\n",
    "                moved_dir = model_dir + \"_\" + dt_now + \"_bak\"\n",
    "                shutil.move(model_dir, moved_dir)\n",
    "                print(\"--- Moved to {}\".format(moved_dir))\n",
    "            else:\n",
    "                shutil.rmtree(model_dir)\n",
    "\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "            \n",
    "    def train(self, x_train, y_train):\n",
    "        batch_size = self.config.get(TRAIN, \"batch_size\")\n",
    "        epochs = self.config.get(TRAIN, \"epochs\")\n",
    "        patience = self.config.get(TRAIN, \"patience\")\n",
    "        eval_dir = self.config.get(TRAIN, \"eval_dir\")\n",
    "        model_dir = self.config.get(TRAIN, \"model_dir\")\n",
    "        metrics = [\"accuracy\", \"val_accuracy\"]\n",
    "        try:\n",
    "            metrics = self.config.get(TRAIN, \"metrics\")\n",
    "        except:\n",
    "            pass\n",
    "        self.create_dirs(eval_dir, model_dir)\n",
    "        # Copy current config_file to model_dir\n",
    "        shutil.copy2(self.config_file, model_dir)\n",
    "        print(\"-- Copied {} to {}\".format(self.config_file, model_dir))\n",
    "\n",
    "        weight_filepath = os.path.join(model_dir, BEST_MODEL_FILE)\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=patience, verbose=1)\n",
    "        check_point = ModelCheckpoint(weight_filepath, verbose=1, save_best_only=True)\n",
    "        epoch_change = EpochChangeCallback(eval_dir, metrics)\n",
    "\n",
    "        results = self.model.fit(x_train, y_train,\n",
    "                                 validation_split=0.2, batch_size=batch_size, epochs=epochs,\n",
    "                                 shuffle=False,\n",
    "                                 callbacks=[early_stopping, check_point, epoch_change],\n",
    "                                 verbose=1)\n",
    "\n",
    "    def load_model(self):\n",
    "        rc = False\n",
    "        if not self.model_loaded:\n",
    "            model_dir = self.config.get(TRAIN, \"model_dir\")\n",
    "            weight_filepath = \"./models/best_model.h5\"\n",
    "            if os.path.exists(weight_filepath):\n",
    "                self.model.load_weights(weight_filepath)\n",
    "                self.model_loaded = True\n",
    "                print(\"=== Loaded a weight_file {}\".format(weight_filepath))\n",
    "                rc = True\n",
    "            else:\n",
    "                message = \"Not found a weight_file \" + weight_filepath\n",
    "                raise Exception(message)\n",
    "        else:\n",
    "            pass\n",
    "            # print(\"== Already loaded a weight file.\")\n",
    "        return rc\n",
    "    \n",
    "    def infer(self, input_dir, output_dir, expand=True):\n",
    "        writer = GrayScaleImageWriter()\n",
    "        # We are interested in png and jpg files.\n",
    "        image_files = glob.glob(input_dir + \"/*.png\")\n",
    "        image_files += glob.glob(input_dir + \"/*.jpg\")\n",
    "        image_files += glob.glob(input_dir + \"/*.tif\")\n",
    "        # 2023/05/15 Added *.bmp files\n",
    "        image_files += glob.glob(input_dir + \"/*.bmp\")\n",
    "\n",
    "        width = self.config.get(MODEL, \"image_width\")\n",
    "        height = self.config.get(MODEL, \"image_height\")\n",
    "\n",
    "        merged_dir = None\n",
    "        try:\n",
    "            merged_dir = self.config.get(INFER, \"merged_dir\")\n",
    "            if os.path.exists(merged_dir):\n",
    "                shutil.rmtree(merged_dir)\n",
    "            if not os.path.exists(merged_dir):\n",
    "                os.makedirs(merged_dir)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for image_file in image_files:\n",
    "            basename = os.path.basename(image_file)\n",
    "            name = basename.split(\".\")[0]\n",
    "            # <fixed> 2023/07/15 to avoid error on png file\n",
    "            img = cv2.imread(image_file)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # </fixed>\n",
    "\n",
    "            h = img.shape[0]\n",
    "            w = img.shape[1]\n",
    "            # Any way, we have to resize the input image to match the input size of our TensorflowUNet model.\n",
    "            img = cv2.resize(img, (width, height))\n",
    "            predictions = self.predict([img], expand=expand)\n",
    "            prediction = predictions[0]\n",
    "            image = prediction[0]\n",
    "            # Resize the predicted image to be the original image size (w, h), and save it as a grayscale image.\n",
    "            # Probably, this is a natural way for all humans.\n",
    "            mask = writer.save_resized(image, (w, h), output_dir, name)\n",
    "\n",
    "            print(\"--- image_file {}\".format(image_file))\n",
    "            if merged_dir is not None:\n",
    "                # Resize img to the original size (w, h)\n",
    "                img = cv2.resize(img, (w, h))\n",
    "                img += mask\n",
    "                merged_file = os.path.join(merged_dir, basename)\n",
    "                cv2.imwrite(merged_file, img)\n",
    "                \n",
    "    def predict(self, images, expand=True):\n",
    "        self.load_model()\n",
    "        predictions = []\n",
    "        for image in images:\n",
    "            # print(\"=== Input image shape {}\".format(image.shape))\n",
    "            if expand:\n",
    "                image = np.expand_dims(image, 0)\n",
    "            pred = self.model.predict(image)\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "    def infer_tiles(self, input_dir, output_dir, expand=True):\n",
    "        image_files = glob.glob(input_dir + \"/*.png\")\n",
    "        image_files += glob.glob(input_dir + \"/*.jpg\")\n",
    "        image_files += glob.glob(input_dir + \"/*.tif\")\n",
    "        image_files += glob.glob(input_dir + \"/*.bmp\")\n",
    "        MARGIN = self.config.get(TILEDINFER, \"overlapping\", dvalue=0)\n",
    "        print(\"MARGIN {}\".format(MARGIN))\n",
    "\n",
    "        merged_dir = None\n",
    "        try:\n",
    "            merged_dir = self.config.get(TILEDINFER, \"merged_dir\")\n",
    "            if os.path.exists(merged_dir):\n",
    "                shutil.rmtree(merged_dir)\n",
    "            if not os.path.exists(merged_dir):\n",
    "                os.makedirs(merged_dir)\n",
    "        except:\n",
    "            pass\n",
    "        split_size = self.config.get(MODEL, \"image_width\")\n",
    "        print(\"---split_size {}\".format(split_size))\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image = Image.open(image_file)\n",
    "            w, h = image.size\n",
    "\n",
    "            vert_split_num = h // split_size\n",
    "            if h % split_size != 0:\n",
    "                vert_split_num += 1\n",
    "\n",
    "            horiz_split_num = w // split_size\n",
    "            if w % split_size != 0:\n",
    "                horiz_split_num += 1\n",
    "\n",
    "            bgcolor = self.config.get(TILEDINFER, \"background\", dvalue=0)\n",
    "            print(\"=== bgcolor {}\".format(bgcolor))\n",
    "            background = Image.new(\"L\", (w, h), bgcolor)\n",
    "\n",
    "            for j in range(vert_split_num):\n",
    "                for i in range(horiz_split_num):\n",
    "                    left = split_size * i\n",
    "                    upper = split_size * j\n",
    "                    right = left + split_size\n",
    "                    lower = upper + split_size\n",
    "\n",
    "                    if left >= w or upper >= h:\n",
    "                        continue\n",
    "\n",
    "                    left_margin = MARGIN\n",
    "                    upper_margin = MARGIN\n",
    "                    if left - MARGIN < 0:\n",
    "                        left_margin = 0\n",
    "                    if upper - MARGIN < 0:\n",
    "                        upper_margin = 0\n",
    "\n",
    "                    cropped = image.crop((left - left_margin, upper - upper_margin, right + MARGIN, lower + MARGIN))\n",
    "                    cw, ch = cropped.size\n",
    "                    cropped = cropped.resize((split_size, split_size))\n",
    "                    predictions = self.predict([cropped], expand=expand)\n",
    "                    prediction = predictions[0]\n",
    "                    mask = prediction[0]\n",
    "\n",
    "                    img = self.mask_to_image(mask)\n",
    "                    img = img.resize((cw, ch))\n",
    "\n",
    "                    img = img.convert(\"L\")\n",
    "\n",
    "                    ww, hh = img.size\n",
    "                    img = img.crop((left_margin, upper_margin, ww - left_margin, hh - upper_margin))\n",
    "\n",
    "                    ww, hh = img.size\n",
    "                    background.paste(img, (left, upper))\n",
    "                    print(\"---paste j:{} i:{} ww:{} hh:{}\".format(j, i, ww, hh))\n",
    "\n",
    "            basename = os.path.basename(image_file)\n",
    "            output_file = os.path.join(output_dir, basename)\n",
    "            background.save(output_file)\n",
    "\n",
    "            if merged_dir is not None:\n",
    "                img = np.array(image)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                mask = np.array(background)\n",
    "                mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "                img += mask\n",
    "\n",
    "                merged_file = os.path.join(merged_dir, basename)\n",
    "                cv2.imwrite(merged_file, img)\n",
    "\n",
    "    def mask_to_image(self, data, factor=255.0):\n",
    "        h = data.shape[0]\n",
    "        w = data.shape[1]\n",
    "\n",
    "        data = data * factor\n",
    "        data = data.reshape([w, h])\n",
    "        image = Image.fromarray(data)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        self.load_model()\n",
    "        score = self.model.evaluate(x_test, y_test, verbose=1)\n",
    "        print(\"Test loss    :{}\".format(round(score[0], 4)))\n",
    "        print(\"Test accuracy:{}\".format(round(score[1], 4)))\n",
    "\n",
    "\n",
    "    def inspect(self, image_file='./model.png', summary_file=\"./summary.txt\"):\n",
    "\n",
    "        tf.keras.utils.plot_model(self.model, to_file=image_file, show_shapes=True)\n",
    "        print(\"=== Saved model graph as an image_file {}\".format(image_file))\n",
    "        with open(summary_file, 'w') as f:\n",
    "            self.model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "        print(\"=== Saved model summary as a text_file {}\".format(summary_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eafea259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== ConfigParser ./train_eval_infer.config\n",
      "{'eval': {'image_datapath': '\"./Mammogram/valid/images\"',\n",
      "          'mask_datapath': '\"./Mammogram/valid/masks\"',\n",
      "          'output_dir': '\"./eval_output\"'},\n",
      " 'infer': {'images_dir': '\".//Mammogram/test/images\"',\n",
      "           'merged_dir': '\"./mini_test_output_merged\"',\n",
      "           'output_dir': '\"./mini_test_output\"'},\n",
      " 'mask': {'binarize': 'True', 'blur': 'True', 'threshold': '74'},\n",
      " 'model': {'base_filters': '16',\n",
      "           'base_kernels': '(7,7)',\n",
      "           'clipvalue': '0.5',\n",
      "           'dilation': '(2,2)',\n",
      "           'dropout_rate': '0.06',\n",
      "           'image_channels': '3',\n",
      "           'image_height': '512',\n",
      "           'image_width': '512',\n",
      "           'learning_rate': '0.0001',\n",
      "           'loss': '\"bce_iou_loss\"',\n",
      "           'metrics': '[\"iou_coef\"]',\n",
      "           'num_classes': '1',\n",
      "           'num_layers': '7',\n",
      "           'show_summary': 'False'},\n",
      " 'train': {'batch_size': '2',\n",
      "           'create_backup': 'False',\n",
      "           'epochs': '1',\n",
      "           'eval_dir': '\"./eval\"',\n",
      "           'image_datapath': '\"./Mammogram/train/images\"',\n",
      "           'mask_datapath': '\"./Mammogram/train/masks\"',\n",
      "           'metrics': '[\"iou_coef\", \"val_iou_coef\"]',\n",
      "           'model_dir': '\"./models\"',\n",
      "           'patience': '10'}}\n",
      "=== set seed 137\n",
      "==== ConfigParser ./train_eval_infer.config\n",
      "{'eval': {'image_datapath': '\"./Mammogram/valid/images\"',\n",
      "          'mask_datapath': '\"./Mammogram/valid/masks\"',\n",
      "          'output_dir': '\"./eval_output\"'},\n",
      " 'infer': {'images_dir': '\".//Mammogram/test/images\"',\n",
      "           'merged_dir': '\"./mini_test_output_merged\"',\n",
      "           'output_dir': '\"./mini_test_output\"'},\n",
      " 'mask': {'binarize': 'True', 'blur': 'True', 'threshold': '74'},\n",
      " 'model': {'base_filters': '16',\n",
      "           'base_kernels': '(7,7)',\n",
      "           'clipvalue': '0.5',\n",
      "           'dilation': '(2,2)',\n",
      "           'dropout_rate': '0.06',\n",
      "           'image_channels': '3',\n",
      "           'image_height': '512',\n",
      "           'image_width': '512',\n",
      "           'learning_rate': '0.0001',\n",
      "           'loss': '\"bce_iou_loss\"',\n",
      "           'metrics': '[\"iou_coef\"]',\n",
      "           'num_classes': '1',\n",
      "           'num_layers': '7',\n",
      "           'show_summary': 'False'},\n",
      " 'train': {'batch_size': '2',\n",
      "           'create_backup': 'False',\n",
      "           'epochs': '1',\n",
      "           'eval_dir': '\"./eval\"',\n",
      "           'image_datapath': '\"./Mammogram/train/images\"',\n",
      "           'mask_datapath': '\"./Mammogram/train/masks\"',\n",
      "           'metrics': '[\"iou_coef\", \"val_iou_coef\"]',\n",
      "           'model_dir': '\"./models\"',\n",
      "           'patience': '10'}}\n",
      "Input image_height 512 image_width 512 image_channels 3\n",
      "=== WARNING: Not found [model]  normalization, return default value False\n",
      "--- normalization False\n",
      "--- kernel_size   [(7, 7), (5, 5), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
      "--- rkernel_size  [(3, 3), (3, 3), (3, 3), (3, 3), (5, 5), (7, 7)]\n",
      "=== dilations  [(2, 2), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]\n",
      "=== rdilations [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 2)]\n",
      "--- kernel_size (7, 7)\n",
      "--- dilation (2, 2)\n",
      "--- kernel_size (5, 5)\n",
      "--- dilation (1, 1)\n",
      "--- kernel_size (3, 3)\n",
      "--- dilation (1, 1)\n",
      "--- kernel_size (3, 3)\n",
      "--- dilation (1, 1)\n",
      "--- kernel_size (3, 3)\n",
      "--- dilation (1, 1)\n",
      "--- kernel_size (3, 3)\n",
      "--- dilation (1, 1)\n",
      "--- kernel_size (3, 3)\n",
      "--- dilation (1, 1)\n",
      "+++ kernel_size (3, 3)\n",
      "+++ dilation (1, 1)\n",
      "+++ kernel_size (3, 3)\n",
      "+++ dilation (1, 1)\n",
      "+++ kernel_size (3, 3)\n",
      "+++ dilation (1, 1)\n",
      "+++ kernel_size (3, 3)\n",
      "+++ dilation (1, 1)\n",
      "+++ kernel_size (5, 5)\n",
      "+++ dilation (1, 1)\n",
      "+++ kernel_size (7, 7)\n",
      "+++ dilation (2, 2)\n",
      "=== Optimizer Adam learning_rate 0.0001 clipvalue 0.5\n",
      "--- loss    <function bce_iou_loss at 0x0000021C1DCBD550>\n",
      "--- metrics [<function iou_coef at 0x0000021C1DCBD310>]\n",
      "=== Loaded a weight_file ./models/best_model.h5\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P126_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P126_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 612ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P145_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P145_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 556ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P152_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P152_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 566ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P155_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P155_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P163_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P163_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 619ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P169_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P169_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 567ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P177_R_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P177_R_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 595ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P184_R_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P184_R_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 582ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P188_R_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P188_R_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 610ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P195_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P195_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 555ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P218_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P218_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 587ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P239_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P239_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 559ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P245_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P245_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 574ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P253_R_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P253_R_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 628ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P255_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P255_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 650ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P258_R_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P258_R_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P260_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P260_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 708ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P268_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P268_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 632ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P272_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P272_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 783ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P286_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P286_R_DM_CC.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 620ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P299_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P299_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 566ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P310_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P310_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 621ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P312_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P312_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 576ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P314_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P314_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 640ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P318_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P318_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 587ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P321_R_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P321_R_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 550ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P326_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P326_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 625ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P3_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P3_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 589ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P56_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P56_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 620ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\flipped_P59_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\flipped_P59_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 719ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P123_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P123_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 752ms/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P126_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P126_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P129_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P129_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P12_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P12_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P152_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P152_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P163_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P163_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P177_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P177_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P206_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P206_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P211_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P211_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P212_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P212_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P221_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P221_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P257_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P257_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P260_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P260_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P265_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P265_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P26_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P26_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P273_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P273_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P283_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P283_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P285_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P285_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P288_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P288_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P297_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P297_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P298_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P298_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P305_R_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P305_R_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P313_R_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P313_R_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P315_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P315_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P37_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P37_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P51_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P51_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P56_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P56_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P83_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P83_L_DM_CC.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\mirrored_P85_R_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\mirrored_P85_R_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P113_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P113_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P12_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P12_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P137_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P137_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P138_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P138_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P165_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P165_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P173_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P173_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P186_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P186_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P188_R_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P188_R_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P1_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P1_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P214_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P214_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P223_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P223_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P233_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P233_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P233_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P233_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P255_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P255_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P258_R_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P258_R_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P261_L_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P261_L_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P266_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P266_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P276_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P276_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P280_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P280_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P285_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P285_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P288_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P288_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P28_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P28_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P291_R_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P291_R_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P298_L_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P298_L_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P298_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P298_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P299_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P299_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P305_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P305_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P307_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P307_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P308_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P308_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P323_L_DM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P323_L_DM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P326_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P326_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P38_R_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P38_R_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P53_R_CM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P53_R_CM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P64_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P64_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P82_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P82_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P83_L_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P83_L_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P90_R_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P90_R_CM_MLO.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P90_R_DM_CC.jpg\n",
      "--- image_file .//Mammogram/test/images\\P90_R_DM_CC.jpg\n",
      "1/1 [==============================] - 1s 1s/step\n",
      " image w: 512 h: 512\n",
      "== resized to (512, 512)\n",
      "=== Saved ./mini_test_output\\P99_R_CM_MLO.jpg\n",
      "--- image_file .//Mammogram/test/images\\P99_R_CM_MLO.jpg\n"
     ]
    }
   ],
   "source": [
    "config_file = \"./train_eval_infer.config\"\n",
    "if len(sys.argv) == 2:\n",
    "    config_file = sys.argv[1]\n",
    "config = ConfigParser(config_file)\n",
    "images_dir = config.get(INFER, \"images_dir\")\n",
    "output_dir = config.get(INFER, \"output_dir\")\n",
    "\n",
    "model = TensorflowUNet(config_file)\n",
    "\n",
    "if not os.path.exists(images_dir):\n",
    "    raise Exception(\"Not found \" + images_dir)\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "model.infer(images_dir, output_dir, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08d67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794204d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a010f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
